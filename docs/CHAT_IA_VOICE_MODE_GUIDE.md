# TITANEâˆ v12 - Chat IA & Voice Mode
## Documentation ComplÃ¨te

### ğŸ¯ Vue d'ensemble

TITANEâˆ v12 intÃ¨gre un systÃ¨me de **Chat IA complet** et un **Voice Mode** rÃ©volutionnaire avec :

- âœ… **Double IA** : Gemini (online) + Ollama (offline local)
- âœ… **Fallback automatique** : Bascule intelligente selon disponibilitÃ©
- âœ… **MÃ©moire cryptÃ©e** : AES-256-GCM + Argon2id
- âœ… **TTS hybride** : Google TTS / Coqui / Piper / espeak
- âœ… **ASR offline** : Whisper / Vosk
- âœ… **Voice Activity Detection** : DÃ©tection automatique de la parole
- âœ… **Modules TITANEâˆ** : Helios, Nexus, Harmonia, Sentinel, AdaptiveEngine, SelfHeal

---

## ğŸ“ Architecture

```
TITANE_INFINITY/
â”œâ”€â”€ src-tauri/src/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ mod.rs          # Types AI
â”‚   â”‚   â”œâ”€â”€ gemini.rs       # API Gemini
â”‚   â”‚   â”œâ”€â”€ ollama.rs       # Ollama local
â”‚   â”‚   â””â”€â”€ router.rs       # Routage intelligent
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ mod.rs          # Types mÃ©moire
â”‚   â”‚   â”œâ”€â”€ encryption.rs   # AES-256-GCM + Argon2
â”‚   â”‚   â”œâ”€â”€ storage.rs      # Persistance cryptÃ©e
â”‚   â”‚   â””â”€â”€ model.rs        # ModÃ¨les donnÃ©es
â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â”œâ”€â”€ mod.rs          # Types TTS
â”‚   â”‚   â”œâ”€â”€ online_tts.rs   # TTS cloud
â”‚   â”‚   â””â”€â”€ local_tts.rs    # TTS offline
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ mod.rs          # Types audio
â”‚   â”‚   â”œâ”€â”€ vad.rs          # Voice Activity Detection
â”‚   â”‚   â”œâ”€â”€ recorder.rs     # Capture micro
â”‚   â”‚   â””â”€â”€ asr.rs          # Reconnaissance vocale
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ mod.rs          # Types modules
â”‚   â”‚   â”œâ”€â”€ helios.rs       # Orchestration
â”‚   â”‚   â”œâ”€â”€ nexus.rs        # Communication
â”‚   â”‚   â”œâ”€â”€ harmonia.rs     # Ã‰quilibrage Ã©motionnel
â”‚   â”‚   â”œâ”€â”€ sentinel.rs     # SÃ©curitÃ©
â”‚   â”‚   â”œâ”€â”€ adaptive.rs     # Adaptation dynamique
â”‚   â”‚   â””â”€â”€ selfheal.rs     # Auto-rÃ©paration
â”‚   â””â”€â”€ commands/
â”‚       â””â”€â”€ ai_chat.rs      # Commandes Tauri
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useAI.ts        # Hook IA
â”‚   â”‚   â”œâ”€â”€ useMemory.ts    # Hook mÃ©moire
â”‚   â”‚   â”œâ”€â”€ useConnection.ts # Hook connexion
â”‚   â”‚   â””â”€â”€ useVoiceMode.ts # Hook voice
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ ChatWindow.tsx  # Interface chat
â”‚       â”œâ”€â”€ MessageBubble.tsx # Bulle message
â”‚       â”œâ”€â”€ StatusIndicator.tsx # Statut IA
â”‚       â”œâ”€â”€ AudioButton.tsx # Bouton TTS
â”‚       â”œâ”€â”€ VoiceUI.tsx     # Interface vocale
â”‚       â””â”€â”€ VADIndicator.tsx # Indicateur VAD
```

---

## ğŸš€ Installation

### PrÃ©requis

```bash
# Rust + Cargo
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Node.js + npm
# https://nodejs.org/

# Ollama (optionnel, pour mode offline)
curl https://ollama.ai/install.sh | sh
ollama pull llama3

# Whisper (optionnel, pour ASR offline)
pip install openai-whisper

# TTS local (optionnel)
sudo apt install espeak  # Linux
```

### Configuration

1. **CrÃ©er fichier `.env`** Ã  la racine :

```env
GEMINI_API_KEY=votre_cle_api_gemini
OLLAMA_MODEL=llama3
```

2. **Installer dÃ©pendances** :

```bash
cd TITANE_INFINITY
npm install
```

3. **Build & Run** :

```bash
npm run tauri dev
```

---

## ğŸ’¡ Utilisation

### Chat IA Basique

```typescript
import { useAI } from '@/hooks/useAI';

function MyComponent() {
  const { query, messages, isLoading, status } = useAI();

  const handleSend = async () => {
    await query("Comment fonctionne TITANEâˆ?");
  };

  return (
    <div>
      {messages.map(msg => (
        <div key={msg.id}>{msg.content}</div>
      ))}
      <button onClick={handleSend}>Envoyer</button>
    </div>
  );
}
```

### MÃ©moire Conversationnelle

```typescript
import { useMemory } from '@/hooks/useMemory';

function MemoryComponent() {
  const { 
    conversations, 
    createConversation, 
    loadConversation 
  } = useMemory();

  const createNew = async () => {
    const id = await createConversation("Ma conversation");
    console.log("CrÃ©Ã©e:", id);
  };

  return (
    <div>
      {conversations.map(conv => (
        <div key={conv.id}>{conv.title}</div>
      ))}
    </div>
  );
}
```

### Voice Mode

```typescript
import { useVoiceMode } from '@/hooks/useVoiceMode';

function VoiceComponent() {
  const { 
    state, 
    startRecording, 
    stopRecording, 
    speak 
  } = useVoiceMode();

  return (
    <div>
      <button onClick={startRecording}>ğŸ¤ Start</button>
      <button onClick={stopRecording}>â¹ Stop</button>
      {state.transcript && <p>{state.transcript}</p>}
      <button onClick={() => speak("Bonjour TITANE")}>
        ğŸ”Š Speak
      </button>
    </div>
  );
}
```

---

## ğŸ”§ API Tauri

### Commandes disponibles

#### `ai_query`
Query l'IA (Gemini ou Ollama)

```rust
invoke('ai_query', {
  prompt: "Question",
  temperature: 0.7,
  maxTokens: 2000
})
```

#### `speak`
SynthÃ¨se vocale

```rust
invoke('speak', {
  text: "Texte Ã  lire",
  useOnline: true
})
```

#### `create_conversation`
CrÃ©er une conversation

```rust
invoke('create_conversation', {
  title: "Titre"
})
```

#### `load_conversation`
Charger une conversation

```rust
invoke('load_conversation', {
  conversationId: "uuid"
})
```

#### `health_check`
VÃ©rifier l'Ã©tat du systÃ¨me

```rust
invoke('health_check')
```

#### `start_recording` / `stop_recording`
ContrÃ´le enregistrement audio

```rust
invoke('start_recording')
invoke('stop_recording')
```

#### `transcribe_audio`
Transcription audio vers texte

```rust
invoke('transcribe_audio', {
  audioData: [u8 array]
})
```

---

## ğŸ§  Modules TITANEâˆ

### Helios (Orchestration)
Coordonne les flux IA et l'exÃ©cution des tÃ¢ches.

### Nexus (Communication)
Hub de communication entre IA et modules internes.

### Harmonia (Ã‰quilibrage)
Balance Ã©motionnelle et cohÃ©rence conversationnelle.

### Sentinel (SÃ©curitÃ©)
Filtre les contenus dangereux et dÃ©tecte les injections.

### AdaptiveEngine (Adaptation)
Ajuste dynamiquement tempÃ©rature, tokens, style selon contexte.

### SelfHeal (Auto-rÃ©paration)
DÃ©tecte et rÃ©pare automatiquement les pannes.

---

## ğŸ” SÃ©curitÃ©

### Chiffrement MÃ©moire
- **Algorithme** : AES-256-GCM
- **DÃ©rivation clÃ©** : Argon2id (simplified avec SHA256)
- **Stockage** : `~/.local/share/titane/memory/*.json.enc`

### Sentinel Protection
- Command injection
- SQL injection
- XSS
- Prompt injection
- DonnÃ©es sensibles

---

## ğŸŒ Mode Offline Garanti

Le systÃ¨me fonctionne **toujours**, mÃªme sans internet :

1. **Pas d'internet** â†’ Bascule automatiquement sur **Ollama**
2. **Ollama indisponible** â†’ Erreur claire, pas de crash
3. **TTS offline** : espeak, festival, piper
4. **ASR offline** : Whisper local

---

## ğŸ“Š Tests

### Tester Gemini
```bash
export GEMINI_API_KEY="your-key"
npm run tauri dev
```

### Tester Ollama
```bash
ollama serve
ollama pull llama3
npm run tauri dev
```

### Tester Fallback
1. DÃ©connecter internet
2. L'app bascule sur Ollama
3. Reconnecter â†’ rebascule sur Gemini

---

## ğŸ¨ Personnalisation

### Changer modÃ¨le Ollama
```env
OLLAMA_MODEL=mistral
```

### Ajuster tempÃ©rature IA
```typescript
await query("Question", 0.9, 3000);  // temp=0.9, max_tokens=3000
```

### Changer voix TTS
Modifier `local_tts.rs` pour utiliser Piper/Coqui.

---

## ğŸ› Debug

### Logs Rust
```bash
RUST_LOG=debug npm run tauri dev
```

### Logs Frontend
Ouvrir DevTools : `Cmd+Option+I` (Mac) / `F12` (Linux/Win)

### Tester module isolÃ©ment
```rust
#[cfg(test)]
mod tests {
    #[tokio::test]
    async fn test_ai_router() {
        let router = AIRouter::new(None, None);
        assert!(router.is_ok());
    }
}
```

---

## ğŸ“ˆ Roadmap

- [ ] Streaming rÃ©el (SSE) Gemini
- [ ] IntÃ©gration Whisper natif (sans CLI)
- [ ] Support multilingue complet
- [ ] Export conversations (PDF, Markdown)
- [ ] Fine-tuning Ollama personnalisÃ©
- [ ] Voice Mode continu (PTT ou VAD permanent)

---

## ğŸ¤ Contribution

Le code est modulaire et documentÃ©. Pour contribuer :

1. Fork le projet
2. CrÃ©er une branche : `git checkout -b feature/ma-feature`
3. Commit : `git commit -m 'Add feature'`
4. Push : `git push origin feature/ma-feature`
5. Pull Request

---

## ğŸ“ Licence

MIT License - TITANE Team 2025

---

## âœ¨ CrÃ©dits

- **Gemini** : Google AI
- **Ollama** : Ollama.ai
- **Whisper** : OpenAI
- **Tauri** : Tauri.app
- **React** : Meta

---

**TITANEâˆ CHAT IA â€” Architecture + Modules + API + MÃ©moire + TTS entiÃ¨rement gÃ©nÃ©rÃ©s et prÃªts au dÃ©veloppement.**
